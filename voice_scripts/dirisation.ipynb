{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import datetime\n",
    "import speechbrain\n",
    "import subprocess\n",
    "\n",
    "import torch\n",
    "import pyannote.audio\n",
    "from pyannote.audio.pipelines.speaker_verification import PretrainedSpeakerEmbedding\n",
    "#embedding_model = PretrainedSpeakerEmbedding( \n",
    "#    \"speechbrain/spkrec-ecapa-voxceleb\",\n",
    "#    device=torch.device(\"cuda\"))\n",
    "\n",
    "from pyannote.audio import Audio\n",
    "from pyannote.core import Segment\n",
    "\n",
    "import wave\n",
    "import contextlib\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "'speechbrain' must be installed to use 'speechbrain/spkrec-ecapa-voxceleb' embeddings. Visit https://speechbrain.github.io for installation instructions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyannote\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipelines\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspeaker_verification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedSpeakerEmbedding\n\u001b[0;32m----> 2\u001b[0m embedding_model \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedSpeakerEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspeechbrain/spkrec-ecapa-voxceleb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/pipelines/speaker_verification.py:750\u001b[0m, in \u001b[0;36mPretrainedSpeakerEmbedding\u001b[0;34m(embedding, device, use_auth_token)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PyannoteAudioPretrainedSpeakerEmbedding(\n\u001b[1;32m    746\u001b[0m         embedding, device\u001b[38;5;241m=\u001b[39mdevice, use_auth_token\u001b[38;5;241m=\u001b[39muse_auth_token\n\u001b[1;32m    747\u001b[0m     )\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embedding, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeechbrain\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m embedding:\n\u001b[0;32m--> 750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSpeechBrainPretrainedSpeakerEmbedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embedding, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnvidia\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m embedding:\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NeMoPretrainedSpeakerEmbedding(embedding, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyannote/audio/pipelines/speaker_verification.py:241\u001b[0m, in \u001b[0;36mSpeechBrainPretrainedSpeakerEmbedding.__init__\u001b[0;34m(self, embedding, device, use_auth_token)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    236\u001b[0m     embedding: Text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeechbrain/spkrec-ecapa-voxceleb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    237\u001b[0m     device: Optional[torch\u001b[38;5;241m.\u001b[39mdevice] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    238\u001b[0m     use_auth_token: Union[Text, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    239\u001b[0m ):\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SPEECHBRAIN_IS_AVAILABLE:\n\u001b[0;32m--> 241\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeechbrain\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be installed to use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m embeddings. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisit https://speechbrain.github.io for installation instructions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m         )\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m embedding:\n",
      "\u001b[0;31mImportError\u001b[0m: 'speechbrain' must be installed to use 'speechbrain/spkrec-ecapa-voxceleb' embeddings. Visit https://speechbrain.github.io for installation instructions."
     ]
    }
   ],
   "source": [
    "from pyannote.audio.pipelines.speaker_verification import PretrainedSpeakerEmbedding\n",
    "embedding_model = PretrainedSpeakerEmbedding( \n",
    "    \"speechbrain/spkrec-ecapa-voxceleb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, mp3, from 'random_data/Mike Shinoda - Bleed It Out (Already Over Sessions).mp3':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:02:35.26, start: 0.023021, bitrate: 192 kb/s\n",
      "  Stream #0:0: Audio: mp3, 48000 Hz, stereo, fltp, 192 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'audio.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 pcm_s16le\n",
      "size=   29105kB time=00:02:35.20 bitrate=1536.2kbits/s speed= 621x    \n",
      "video:0kB audio:29105kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000262%\n"
     ]
    }
   ],
   "source": [
    "path = 'random_data/Mike Shinoda - Bleed It Out (Already Over Sessions).mp3'\n",
    "if path[-3:] != 'wav':\n",
    "  subprocess.call(['ffmpeg', '-i', path, 'audio.wav', '-y'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file starts with a 'RIFF' ID.\n"
     ]
    }
   ],
   "source": [
    "def check_riff_id(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        header = file.read(4)\n",
    "        return header == b'RIFF'\n",
    "\n",
    "path = 'audio.wav'\n",
    "if check_riff_id(path):\n",
    "    print(\"The file starts with a 'RIFF' ID.\")\n",
    "else:\n",
    "    print(\"The file does not start with a 'RIFF' ID.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size='base.en'\n",
    "model = whisper.load_model(model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transcribe(path)\n",
    "segments = result[\"segments\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above code generates timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with contextlib.closing(wave.open(path,'r')) as f:\n",
    "  frames = f.getnframes()\n",
    "  rate = f.getframerate()\n",
    "  duration = frames / float(rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate embeddings for the segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = Audio()\n",
    "\n",
    "def segment_embedding(segment):\n",
    "  start = segment[\"start\"]\n",
    "  # Whisper overshoots the end timestamp in the last segment\n",
    "  end = min(duration, segment[\"end\"])\n",
    "  clip = Segment(start, end)\n",
    "  waveform, sample_rate = audio.crop(path, clip)\n",
    "  return embedding_model(waveform[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(segments), \u001b[38;5;241m192\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, segment \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(segments):\n\u001b[0;32m----> 3\u001b[0m   embeddings[i] \u001b[38;5;241m=\u001b[39m \u001b[43msegment_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan_to_num(embeddings)\n",
      "Cell \u001b[0;32mIn[42], line 9\u001b[0m, in \u001b[0;36msegment_embedding\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m      7\u001b[0m clip \u001b[38;5;241m=\u001b[39m Segment(start, end)\n\u001b[1;32m      8\u001b[0m waveform, sample_rate \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mcrop(path, clip)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43membedding_model\u001b[49m(waveform[\u001b[38;5;28;01mNone\u001b[39;00m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_model' is not defined"
     ]
    }
   ],
   "source": [
    "embeddings = np.zeros(shape=(len(segments), 192))\n",
    "for i, segment in enumerate(segments):\n",
    "  embeddings[i] = segment_embedding(segment)\n",
    "\n",
    "embeddings = np.nan_to_num(embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
